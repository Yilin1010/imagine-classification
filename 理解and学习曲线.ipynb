{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "模型理解and学习曲线.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yilin1010/imagine-classification/blob/master/%E7%90%86%E8%A7%A3and%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9cBDKQDqyiE",
        "colab_type": "text"
      },
      "source": [
        "#学习曲线\n",
        "\n",
        "见logs文件夹\n",
        "\n",
        "![image](https://github.com/Yilin1010/imagine-classification/blob/master/screenshot/11.png)\n",
        "\n",
        "![image](https://github.com/Yilin1010/imagine-classification/blob/master/screenshot/22.png)\n",
        "\n",
        "\n",
        "![image](https://github.com/Yilin1010/imagine-classification/blob/master/screenshot/33.png)\n",
        "\n",
        "![image](https://github.com/Yilin1010/imagine-classification/blob/master/screenshot/5.png)\n",
        "\n",
        "CNN 最高的是  3 convolutional layers 128 nodes\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAddlpCnqPfm",
        "colab_type": "text"
      },
      "source": [
        "#模型理解\n",
        "\n",
        "## Convolutional Neural Networks\n",
        "\n",
        "    用于图像识别，图像分类和物体探测的深度学习方法之一\n",
        "\n",
        "    输入图片,转化为一个 长*宽*d 的数列（RGB d=3 或 grayscale d=1）\n",
        "    处理图片\n",
        "    分为特定的种类（猫，狗，……）\n",
        "    \n",
        " \n",
        "![替代文字](https://miro.medium.com/max/1129/1*XbuW8WuRrAY5pC4t-9DZAQ.jpeg)   \n",
        "\n",
        "\n",
        "* 卷积层 convolution layers\n",
        "    >3种filters/kernels(特征探测器）：Strides，Padding，Non Linearity\n",
        "\n",
        "* pooling \n",
        "\n",
        "* fully connected layers\n",
        ">比起传统的 fully connected 神经网络，每一层 neuron 都连接着下层的所有 neuron，每一层要覆盖下层的整个图像，卷积可以用更少的时间达到同样的效果，同时减少了connectedness、complexity 和 overfitting \n",
        "\n",
        "* Softmax\n",
        ">Softmax 将物体以（0,1）的概率值分类\n",
        "\n",
        "## LSTM —— speical Recurrent Neural Network\n",
        "\n",
        "* Recurrent Neural Network\n",
        "用于解决语音识别，翻译，图像描述imagine captioning\n",
        "\n",
        "\n",
        ">人的思维是persistence，基于之前的信息可以进行目前的理解和推理，传统的 Neural Network 做不到这一点，而 Recurrent Neural Network 通过有**循环**的网络来解决这个问题。\n",
        "\n",
        "* LSTM\n",
        ">RNN 只适合不需要太多语境，相关信息之间的间隔小的情况；LSTM则不存在这个问题 \n",
        "\n",
        "![替代文字](https://miro.medium.com/max/1445/1*wXEZTk3g_UiOgL6VutuBGA.png)\n",
        "![替代文字](https://miro.medium.com/max/1508/1*WOGNu3QcmDipMVPF2yA9wA.png)\n",
        "\n",
        ">在单个重复的结构中，LSTM包含更复杂的四层交互\n",
        "\n",
        "\n",
        "LSTM 的 input 必须是三维（Samples * Time Steps * Features），输入channel-imagine 用 reshape 降维\n",
        "\n",
        "\n",
        "![](https://cdn-images-1.medium.com/freeze/max/1000/0*w2Dh6-nPWtLN2xz6.png?q=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t__QgF6_qPqh",
        "colab_type": "text"
      },
      "source": [
        "## LSTM —— speical Recurrent Neural Network\n",
        "\n",
        "* Recurrent Neural Network\n",
        "用于解决语音识别，翻译，图像描述imagine captioning\n",
        "\n",
        "\n",
        ">人的思维是persistence，基于之前的信息可以进行目前的理解和推理，传统的 Neural Network 做不到这一点，而 Recurrent Neural Network 通过有**循环**的网络来解决这个问题。\n",
        "\n",
        "* LSTM\n",
        ">RNN 只适合不需要太多语境，相关信息之间的间隔小的情况；LSTM则不存在这个问题 \n",
        "\n",
        "![替代文字](https://miro.medium.com/max/1445/1*wXEZTk3g_UiOgL6VutuBGA.png)\n",
        "![替代文字](https://miro.medium.com/max/1508/1*WOGNu3QcmDipMVPF2yA9wA.png)\n",
        "\n",
        ">在单个重复的结构中，LSTM包含更复杂的四层交互\n",
        "\n",
        "\n",
        "LSTM 的 input 必须是三维（Samples * Time Steps * Features），输入channel-imagine 用 reshape 降维\n",
        "\n",
        "\n",
        "![](https://cdn-images-1.medium.com/freeze/max/1000/0*w2Dh6-nPWtLN2xz6.png?q=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bos5tdwMqP0C",
        "colab_type": "text"
      },
      "source": [
        "## 欠拟合\n",
        "\n",
        "RNN\n",
        "\n",
        "![替代文字](https://github.com/Yilin1010/imagine-classification/blob/master/screenshot/loss.png)\n",
        "\n",
        "调整：学习率衰减\n",
        "\n",
        "```\n",
        "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwd15Qd6vSN8",
        "colab_type": "text"
      },
      "source": [
        "refer:\n",
        "\n",
        "CNN\n",
        "\n",
        "1.https://medium.com/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148\n",
        "\n",
        "2.https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1\n",
        "\n",
        "3.https://towardsdatascience.com/the-4-convolutional-neural-network-models-that-can-classify-your-fashion-images-9fe7f3e5399d\n",
        "\n",
        "RNN\n",
        "\n",
        "1.https://medium.com/explore-artificial-intelligence/an-introduction-to-recurrent-neural-networks-72c97bf0912\n",
        "\n",
        "2.https://medium.com/explore-artificial-intelligence/lstm-networks-c300d3cb8ac4\n",
        "\n",
        "LSTN INPUT\n",
        "https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/\n",
        "\n",
        "https://stackoverflow.com/questions/47671732/keras-input-a-3-channel-image-into-lstm"
      ]
    }
  ]
}
