{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"模型理解and学习曲线.ipynb","version":"0.3.2","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"B9cBDKQDqyiE","colab_type":"text"},"source":["#学习曲线\n","\n","见logs文件夹"]},{"cell_type":"code","metadata":{"id":"ox4razesq4jp","colab_type":"code","outputId":"ae43b20d-a1af-4f4f-9f4e-9432490d7176","executionInfo":{"status":"ok","timestamp":1567020724564,"user_tz":-480,"elapsed":1502,"user":{"displayName":"lala la","photoUrl":"","userId":"09668589679038383772"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["#!pip install -q tf-nightly-2.0-preview\n","\n","%load_ext tensorboard\n","log_dir=\"/content/drive/My Drive/Colab Notebooks/dogVScat/PetImages/logs\"\n","%tensorboard --logdir logs"],"execution_count":0,"outputs":[{"output_type":"stream","text":["The tensorboard extension is already loaded. To reload it, use:\n","  %reload_ext tensorboard\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/plain":["Reusing TensorBoard on port 6006 (pid 7915), started 0:07:30 ago. (Use '!kill 7915' to kill it.)"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div id=\"root\"></div>\n","    <script>\n","      (function() {\n","        window.TENSORBOARD_ENV = window.TENSORBOARD_ENV || {};\n","        window.TENSORBOARD_ENV[\"IN_COLAB\"] = true;\n","        document.querySelector(\"base\").href = \"https://localhost:6006\";\n","        function fixUpTensorboard(root) {\n","          const tftb = root.querySelector(\"tf-tensorboard\");\n","          // Disable the fragment manipulation behavior in Colab. Not\n","          // only is the behavior not useful (as the iframe's location\n","          // is not visible to the user), it causes TensorBoard's usage\n","          // of `window.replace` to navigate away from the page and to\n","          // the `localhost:<port>` URL specified by the base URI, which\n","          // in turn causes the frame to (likely) crash.\n","          tftb.removeAttribute(\"use-hash\");\n","        }\n","        function executeAllScripts(root) {\n","          // When `script` elements are inserted into the DOM by\n","          // assigning to an element's `innerHTML`, the scripts are not\n","          // executed. Thus, we manually re-insert these scripts so that\n","          // TensorBoard can initialize itself.\n","          for (const script of root.querySelectorAll(\"script\")) {\n","            const newScript = document.createElement(\"script\");\n","            newScript.type = script.type;\n","            newScript.textContent = script.textContent;\n","            root.appendChild(newScript);\n","            script.remove();\n","          }\n","        }\n","        function setHeight(root, height) {\n","          // We set the height dynamically after the TensorBoard UI has\n","          // been initialized. This avoids an intermediate state in\n","          // which the container plus the UI become taller than the\n","          // final width and cause the Colab output frame to be\n","          // permanently resized, eventually leading to an empty\n","          // vertical gap below the TensorBoard UI. It's not clear\n","          // exactly what causes this problematic intermediate state,\n","          // but setting the height late seems to fix it.\n","          root.style.height = `${height}px`;\n","        }\n","        const root = document.getElementById(\"root\");\n","        fetch(\".\")\n","          .then((x) => x.text())\n","          .then((html) => void (root.innerHTML = html))\n","          .then(() => fixUpTensorboard(root))\n","          .then(() => executeAllScripts(root))\n","          .then(() => setHeight(root, 800));\n","      })();\n","    </script>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"lAddlpCnqPfm","colab_type":"text"},"source":["#模型理解\n","\n","## Convolutional Neural Networks\n","\n","    用于图像识别，图像分类和物体探测的深度学习方法之一\n","\n","    输入图片,转化为一个 长*宽*d 的数列（RGB d=3 或 grayscale d=1）\n","    处理图片\n","    分为特定的种类（猫，狗，……）\n","    \n"," \n","![替代文字](https://miro.medium.com/max/1129/1*XbuW8WuRrAY5pC4t-9DZAQ.jpeg)   \n","\n","\n","* 卷积层 convolution layers\n","    >3种filters/kernels(特征探测器）：Strides，Padding，Non Linearity\n","\n","* pooling \n","\n","* fully connected layers\n",">比起传统的 fully connected 神经网络，每一层 neuron 都连接着下层的所有 neuron，每一层要覆盖下层的整个图像，卷积可以用更少的时间达到同样的效果，同时减少了connectedness、complexity 和 overfitting \n","\n","* Softmax\n",">Softmax 将物体以（0,1）的概率值分类\n","\n","## LSTM —— speical Recurrent Neural Network\n","\n","* Recurrent Neural Network\n","用于解决语音识别，翻译，图像描述imagine captioning\n","\n","\n",">人的思维是persistence，基于之前的信息可以进行目前的理解和推理，传统的 Neural Network 做不到这一点，而 Recurrent Neural Network 通过有**循环**的网络来解决这个问题。\n","\n","* LSTM\n",">RNN 只适合不需要太多语境，相关信息之间的间隔小的情况；LSTM则不存在这个问题 \n","\n","![替代文字](https://miro.medium.com/max/1445/1*wXEZTk3g_UiOgL6VutuBGA.png)\n","![替代文字](https://miro.medium.com/max/1508/1*WOGNu3QcmDipMVPF2yA9wA.png)\n","\n",">在单个重复的结构中，LSTM包含更复杂的四层交互\n","\n","\n","LSTM 的 input 必须是三维（Samples * Time Steps * Features），输入channel-imagine 用 reshape 降维\n","\n","\n","![](https://cdn-images-1.medium.com/freeze/max/1000/0*w2Dh6-nPWtLN2xz6.png?q=20)"]},{"cell_type":"markdown","metadata":{"id":"t__QgF6_qPqh","colab_type":"text"},"source":["## LSTM —— speical Recurrent Neural Network\n","\n","* Recurrent Neural Network\n","用于解决语音识别，翻译，图像描述imagine captioning\n","\n","\n",">人的思维是persistence，基于之前的信息可以进行目前的理解和推理，传统的 Neural Network 做不到这一点，而 Recurrent Neural Network 通过有**循环**的网络来解决这个问题。\n","\n","* LSTM\n",">RNN 只适合不需要太多语境，相关信息之间的间隔小的情况；LSTM则不存在这个问题 \n","\n","![替代文字](https://miro.medium.com/max/1445/1*wXEZTk3g_UiOgL6VutuBGA.png)\n","![替代文字](https://miro.medium.com/max/1508/1*WOGNu3QcmDipMVPF2yA9wA.png)\n","\n",">在单个重复的结构中，LSTM包含更复杂的四层交互\n","\n","\n","LSTM 的 input 必须是三维（Samples * Time Steps * Features），输入channel-imagine 用 reshape 降维\n","\n","\n","![](https://cdn-images-1.medium.com/freeze/max/1000/0*w2Dh6-nPWtLN2xz6.png?q=20)"]},{"cell_type":"markdown","metadata":{"id":"bos5tdwMqP0C","colab_type":"text"},"source":["## 欠拟合\n","\n","RNN\n","![替代文字](https://)\n","\n","调整：学习率衰减\n","\n","```\n","opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"nwd15Qd6vSN8","colab_type":"text"},"source":["refer:\n","\n","CNN\n","\n","1.https://medium.com/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148\n","\n","2.https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1\n","\n","3.https://towardsdatascience.com/the-4-convolutional-neural-network-models-that-can-classify-your-fashion-images-9fe7f3e5399d\n","\n","RNN\n","\n","1.https://medium.com/explore-artificial-intelligence/an-introduction-to-recurrent-neural-networks-72c97bf0912\n","\n","2.https://medium.com/explore-artificial-intelligence/lstm-networks-c300d3cb8ac4\n","\n","LSTN INPUT\n","https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/\n","\n","https://stackoverflow.com/questions/47671732/keras-input-a-3-channel-image-into-lstm"]}]}